{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment02\n",
    "- Student ID : 2012136079\n",
    "- Student Name : 안찬웅\n",
    "- Major : Computer Science Engineering\n",
    "- Professor : 주영복 교수님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mac Address : 98-83-89-2D-5E-D9\n"
     ]
    }
   ],
   "source": [
    "# Mac Address를 얻기 위한 getmac() 함수 정의\n",
    "import uuid\n",
    "\n",
    "def get_mac():\n",
    "  mac_num = hex(uuid.getnode()).replace('0x', '').upper()\n",
    "  mac = '-'.join(mac_num[i : i + 2] for i in range(0, 11, 2))\n",
    "  return mac\n",
    "\n",
    "print (\"Mac Address : \" +get_mac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem01\n",
    "- Code in Lab02-Linear Regression.pptx slide 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.713995 [ 0.98933768] [ 0.46747786]\n",
      "20 0.0547278 [ 1.15056896] [ 0.55336732]\n",
      "40 0.0477826 [ 1.14143312] [ 0.58936763]\n",
      "60 0.0417289 [ 1.1321739] [ 0.6228103]\n",
      "80 0.0364421 [ 1.12351775] [ 0.65406185]\n",
      "100 0.0318252 [ 1.11542845] [ 0.68326676]\n",
      "120 0.0277932 [ 1.10786879] [ 0.71055907]\n",
      "140 0.024272 [ 1.10080445] [ 0.73606384]\n",
      "160 0.0211969 [ 1.09420264] [ 0.75989836]\n",
      "180 0.0185114 [ 1.08803332] [ 0.78217191]\n",
      "200 0.0161662 [ 1.082268] [ 0.80298668]\n",
      "220 0.014118 [ 1.0768801] [ 0.82243836]\n",
      "240 0.0123294 [ 1.07184517] [ 0.84061593]\n",
      "260 0.0107673 [ 1.06713998] [ 0.85760307]\n",
      "280 0.0094032 [ 1.06274295] [ 0.87347788]\n",
      "300 0.00821187 [ 1.05863392] [ 0.88831294]\n",
      "320 0.00717152 [ 1.05479383] [ 0.90217644]\n",
      "340 0.00626294 [ 1.05120564] [ 0.91513187]\n",
      "360 0.00546948 [ 1.04785204] [ 0.92723906]\n",
      "380 0.00477653 [ 1.04471815] [ 0.93855327]\n",
      "400 0.00417137 [ 1.04178953] [ 0.9491266]\n",
      "420 0.0036429 [ 1.03905272] [ 0.95900732]\n",
      "440 0.00318136 [ 1.03649509] [ 0.96824104]\n",
      "460 0.00277831 [ 1.03410494] [ 0.97687]\n",
      "480 0.00242632 [ 1.03187156] [ 0.98493385]\n",
      "500 0.00211892 [ 1.02978408] [ 0.99246979]\n",
      "520 0.00185047 [ 1.02783358] [ 0.99951196]\n",
      "540 0.00161603 [ 1.02601075] [ 1.00609303]\n",
      "560 0.0014113 [ 1.02430725] [ 1.01224291]\n",
      "580 0.00123249 [ 1.02271533] [ 1.01799047]\n",
      "600 0.00107634 [ 1.02122784] [ 1.02336121]\n",
      "620 0.00093998 [ 1.0198375] [ 1.02838027]\n",
      "640 0.00082089 [ 1.01853824] [ 1.0330708]\n",
      "660 0.000716897 [ 1.01732421] [ 1.03745389]\n",
      "680 0.000626069 [ 1.01618969] [ 1.04155004]\n",
      "700 0.000546752 [ 1.01512945] [ 1.04537785]\n",
      "720 0.000477491 [ 1.0141387] [ 1.04895496]\n",
      "740 0.000416994 [ 1.01321268] [ 1.05229795]\n",
      "760 0.000364163 [ 1.01234734] [ 1.05542207]\n",
      "780 0.000318021 [ 1.01153874] [ 1.05834162]\n",
      "800 0.000277732 [ 1.01078308] [ 1.06106985]\n",
      "820 0.000242543 [ 1.01007664] [ 1.06361938]\n",
      "840 0.000211816 [ 1.00941682] [ 1.06600201]\n",
      "860 0.000184984 [ 1.00880027] [ 1.06822836]\n",
      "880 0.000161546 [ 1.00822389] [ 1.07030904]\n",
      "900 0.000141082 [ 1.0076853] [ 1.07225358]\n",
      "920 0.000123206 [ 1.007182] [ 1.07407069]\n",
      "940 0.000107597 [ 1.0067116] [ 1.07576895]\n",
      "960 9.39639e-05 [ 1.00627208] [ 1.07735586]\n",
      "980 8.20603e-05 [ 1.00586128] [ 1.07883871]\n",
      "1000 7.16668e-05 [ 1.00547755] [ 1.08022428]\n",
      "1020 6.25851e-05 [ 1.00511873] [ 1.08151948]\n",
      "1040 5.46569e-05 [ 1.00478351] [ 1.0827297]\n",
      "1060 4.77315e-05 [ 1.00447023] [ 1.08386075]\n",
      "1080 4.16848e-05 [ 1.00417757] [ 1.08491778]\n",
      "1100 3.64031e-05 [ 1.00390399] [ 1.08590555]\n",
      "1120 3.17916e-05 [ 1.00364816] [ 1.08682859]\n",
      "1140 2.7763e-05 [ 1.00340939] [ 1.08769119]\n",
      "1160 2.4246e-05 [ 1.00318599] [ 1.08849728]\n",
      "1180 2.11743e-05 [ 1.00297737] [ 1.08925056]\n",
      "1200 1.84901e-05 [ 1.00278234] [ 1.08995509]\n",
      "1220 1.6147e-05 [ 1.00260007] [ 1.09061289]\n",
      "1240 1.41017e-05 [ 1.00242984] [ 1.09122765]\n",
      "1260 1.23154e-05 [ 1.0022707] [ 1.091802]\n",
      "1280 1.07557e-05 [ 1.00212204] [ 1.0923388]\n",
      "1300 9.39346e-06 [ 1.00198305] [ 1.09284055]\n",
      "1320 8.20356e-06 [ 1.00185323] [ 1.0933094]\n",
      "1340 7.16349e-06 [ 1.00173187] [ 1.09374762]\n",
      "1360 6.2565e-06 [ 1.00161839] [ 1.09415698]\n",
      "1380 5.4631e-06 [ 1.00151241] [ 1.09453964]\n",
      "1400 4.77111e-06 [ 1.00141335] [ 1.09489727]\n",
      "1420 4.16718e-06 [ 1.00132084] [ 1.09523129]\n",
      "1440 3.63977e-06 [ 1.00123441] [ 1.0955435]\n",
      "1460 3.1786e-06 [ 1.00115359] [ 1.09583533]\n",
      "1480 2.77554e-06 [ 1.00107801] [ 1.09610796]\n",
      "1500 2.42436e-06 [ 1.00100744] [ 1.09636271]\n",
      "1520 2.11718e-06 [ 1.00094151] [ 1.09660077]\n",
      "1540 1.84956e-06 [ 1.00088] [ 1.09682322]\n",
      "1560 1.6151e-06 [ 1.00082231] [ 1.09703124]\n",
      "1580 1.41058e-06 [ 1.00076854] [ 1.09722555]\n",
      "1600 1.23171e-06 [ 1.00071812] [ 1.09740734]\n",
      "1620 1.07575e-06 [ 1.00067115] [ 1.0975771]\n",
      "1640 9.39442e-07 [ 1.00062728] [ 1.09773564]\n",
      "1660 8.20417e-07 [ 1.00058603] [ 1.09788382]\n",
      "1680 7.16647e-07 [ 1.00054777] [ 1.09802234]\n",
      "1700 6.25919e-07 [ 1.00051188] [ 1.09815192]\n",
      "1720 5.46621e-07 [ 1.00047839] [ 1.0982728]\n",
      "1740 4.77518e-07 [ 1.00044703] [ 1.09838581]\n",
      "1760 4.17142e-07 [ 1.00041795] [ 1.09849143]\n",
      "1780 3.64337e-07 [ 1.00039053] [ 1.09859014]\n",
      "1800 3.17996e-07 [ 1.0003649] [ 1.09868252]\n",
      "1820 2.77892e-07 [ 1.00034094] [ 1.09876859]\n",
      "1840 2.42676e-07 [ 1.00031888] [ 1.09884918]\n",
      "1860 2.11954e-07 [ 1.0002979] [ 1.09892452]\n",
      "1880 1.85137e-07 [ 1.00027847] [ 1.09899485]\n",
      "1900 1.61709e-07 [ 1.00026023] [ 1.09906054]\n",
      "1920 1.41343e-07 [ 1.00024331] [ 1.09912181]\n",
      "1940 1.23346e-07 [ 1.00022733] [ 1.09917927]\n",
      "1960 1.07823e-07 [ 1.00021255] [ 1.09923291]\n",
      "1980 9.41906e-08 [ 1.00019848] [ 1.0992831]\n",
      "2000 8.22517e-08 [ 1.00018573] [ 1.09932995]\n",
      "Mac Address : 98-83-89-2D-5E-D9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "   cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "       feed_dict={X: [1, 2, 3, 4, 5], \n",
    "                  Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "   if step % 20 == 0:\n",
    "       print(step, cost_val, W_val, b_val)\n",
    "print (\"Mac Address : \" +get_mac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem02\n",
    "- Code in lab-02-1-linear_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.7778 [-0.96830779] [ 0.3041265]\n",
      "20 0.267007 [ 0.44267595] [ 0.8698355]\n",
      "40 0.114998 [ 0.59441298] [ 0.88418376]\n",
      "60 0.103287 [ 0.62542838] [ 0.84788913]\n",
      "80 0.0937961 [ 0.64417011] [ 0.80854219]\n",
      "100 0.0851871 [ 0.66100121] [ 0.77059144]\n",
      "120 0.0773683 [ 0.67694324] [ 0.73438096]\n",
      "140 0.0702671 [ 0.69212669] [ 0.69986814]\n",
      "160 0.0638177 [ 0.70659566] [ 0.66697699]\n",
      "180 0.0579603 [ 0.7203846] [ 0.63563156]\n",
      "200 0.0526404 [ 0.73352545] [ 0.60575932]\n",
      "220 0.0478089 [ 0.74604875] [ 0.57729089]\n",
      "240 0.0434208 [ 0.75798351] [ 0.55016041]\n",
      "260 0.0394355 [ 0.76935744] [ 0.52430493]\n",
      "280 0.0358159 [ 0.78019679] [ 0.49966452]\n",
      "300 0.0325286 [ 0.79052669] [ 0.4761821]\n",
      "320 0.029543 [ 0.80037117] [ 0.45380327]\n",
      "340 0.0268314 [ 0.809753] [ 0.43247619]\n",
      "360 0.0243687 [ 0.81869388] [ 0.4121514]\n",
      "380 0.0221321 [ 0.8272146] [ 0.39278179]\n",
      "400 0.0201007 [ 0.8353349] [ 0.37432241]\n",
      "420 0.0182558 [ 0.84307355] [ 0.35673067]\n",
      "440 0.0165802 [ 0.85044849] [ 0.33996564]\n",
      "460 0.0150584 [ 0.85747701] [ 0.3239885]\n",
      "480 0.0136763 [ 0.8641749] [ 0.30876225]\n",
      "500 0.012421 [ 0.87055826] [ 0.29425156]\n",
      "520 0.011281 [ 0.87664145] [ 0.28042287]\n",
      "540 0.0102455 [ 0.8824389] [ 0.26724398]\n",
      "560 0.00930517 [ 0.88796377] [ 0.25468451]\n",
      "580 0.0084511 [ 0.89322913] [ 0.24271528]\n",
      "600 0.00767544 [ 0.898247] [ 0.23130853]\n",
      "620 0.00697095 [ 0.90302896] [ 0.2204379]\n",
      "640 0.00633113 [ 0.90758616] [ 0.21007816]\n",
      "660 0.00575003 [ 0.91192937] [ 0.20020525]\n",
      "680 0.00522226 [ 0.91606838] [ 0.19079636]\n",
      "700 0.00474295 [ 0.92001289] [ 0.18182962]\n",
      "720 0.00430762 [ 0.92377198] [ 0.17328428]\n",
      "740 0.00391225 [ 0.92735434] [ 0.16514055]\n",
      "760 0.00355317 [ 0.93076849] [ 0.15737958]\n",
      "780 0.00322704 [ 0.93402207] [ 0.14998333]\n",
      "800 0.00293086 [ 0.93712276] [ 0.14293465]\n",
      "820 0.00266185 [ 0.94007784] [ 0.13621722]\n",
      "840 0.00241753 [ 0.94289398] [ 0.12981547]\n",
      "860 0.00219563 [ 0.94557774] [ 0.12371457]\n",
      "880 0.00199412 [ 0.94813538] [ 0.11790045]\n",
      "900 0.00181108 [ 0.95057291] [ 0.11235952]\n",
      "920 0.00164485 [ 0.95289576] [ 0.10707902]\n",
      "940 0.00149389 [ 0.95510948] [ 0.10204671]\n",
      "960 0.00135677 [ 0.95721918] [ 0.09725089]\n",
      "980 0.00123224 [ 0.95922959] [ 0.09268049]\n",
      "1000 0.00111915 [ 0.96114576] [ 0.08832484]\n",
      "1020 0.00101642 [ 0.96297181] [ 0.08417389]\n",
      "1040 0.000923128 [ 0.96471196] [ 0.08021802]\n",
      "1060 0.0008384 [ 0.96637034] [ 0.07644808]\n",
      "1080 0.000761453 [ 0.96795082] [ 0.07285532]\n",
      "1100 0.000691563 [ 0.96945709] [ 0.06943139]\n",
      "1120 0.000628087 [ 0.97089249] [ 0.06616833]\n",
      "1140 0.00057044 [ 0.97226042] [ 0.06305863]\n",
      "1160 0.000518083 [ 0.97356409] [ 0.0600951]\n",
      "1180 0.000470529 [ 0.97480643] [ 0.05727087]\n",
      "1200 0.000427344 [ 0.97599047] [ 0.05457935]\n",
      "1220 0.000388118 [ 0.97711879] [ 0.05201433]\n",
      "1240 0.000352498 [ 0.97819418] [ 0.04956985]\n",
      "1260 0.000320145 [ 0.97921884] [ 0.04724027]\n",
      "1280 0.000290759 [ 0.98019552] [ 0.04502023]\n",
      "1300 0.000264072 [ 0.98112631] [ 0.04290443]\n",
      "1320 0.000239833 [ 0.98201329] [ 0.04088806]\n",
      "1340 0.000217824 [ 0.98285854] [ 0.03896648]\n",
      "1360 0.00019783 [ 0.9836641] [ 0.03713523]\n",
      "1380 0.000179672 [ 0.9844318] [ 0.03539004]\n",
      "1400 0.000163181 [ 0.98516351] [ 0.03372687]\n",
      "1420 0.000148204 [ 0.98586076] [ 0.03214182]\n",
      "1440 0.000134601 [ 0.98652524] [ 0.03063126]\n",
      "1460 0.000122247 [ 0.98715848] [ 0.02919172]\n",
      "1480 0.000111027 [ 0.98776197] [ 0.02781986]\n",
      "1500 0.000100836 [ 0.98833716] [ 0.02651242]\n",
      "1520 9.15818e-05 [ 0.98888522] [ 0.02526643]\n",
      "1540 8.3176e-05 [ 0.98940748] [ 0.02407902]\n",
      "1560 7.5542e-05 [ 0.98990518] [ 0.02294752]\n",
      "1580 6.86083e-05 [ 0.99037981] [ 0.02186912]\n",
      "1600 6.2312e-05 [ 0.99083185] [ 0.02084132]\n",
      "1620 5.6592e-05 [ 0.99126273] [ 0.01986187]\n",
      "1640 5.13984e-05 [ 0.99167341] [ 0.0189284]\n",
      "1660 4.6681e-05 [ 0.99206471] [ 0.01803882]\n",
      "1680 4.23956e-05 [ 0.99243766] [ 0.01719106]\n",
      "1700 3.85045e-05 [ 0.99279302] [ 0.01638312]\n",
      "1720 3.49704e-05 [ 0.99313176] [ 0.01561317]\n",
      "1740 3.17598e-05 [ 0.99345458] [ 0.0148794]\n",
      "1760 2.88448e-05 [ 0.99376214] [ 0.01418011]\n",
      "1780 2.61977e-05 [ 0.99405533] [ 0.01351369]\n",
      "1800 2.3793e-05 [ 0.9943347] [ 0.01287858]\n",
      "1820 2.16092e-05 [ 0.99460089] [ 0.01227335]\n",
      "1840 1.96262e-05 [ 0.99485469] [ 0.01169656]\n",
      "1860 1.78248e-05 [ 0.9950965] [ 0.01114683]\n",
      "1880 1.61885e-05 [ 0.99532694] [ 0.01062297]\n",
      "1900 1.47028e-05 [ 0.99554658] [ 0.01012371]\n",
      "1920 1.33535e-05 [ 0.99575585] [ 0.00964793]\n",
      "1940 1.21275e-05 [ 0.99595529] [ 0.00919453]\n",
      "1960 1.10146e-05 [ 0.99614537] [ 0.00876243]\n",
      "1980 1.00038e-05 [ 0.99632651] [ 0.00835065]\n",
      "2000 9.0856e-06 [ 0.99649918] [ 0.00795824]\n",
      "Mac Address : 98-83-89-2D-5E-D9\n"
     ]
    }
   ],
   "source": [
    "# Lab 2 Linear Regression\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# Try to find values for W and b to compute y_data = x_data * W + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let TensorFlow figure it out\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "print (\"Mac Address : \" +get_mac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem03\n",
    "- Code in lab-02-2-linear_regression_feed.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.1043 [ 0.14130709] [-1.16333449]\n",
      "20 0.156834 [ 1.16660905] [-0.67538244]\n",
      "40 0.0524223 [ 1.25256503] [-0.60238546]\n",
      "60 0.0467946 [ 1.24962556] [-0.57014716]\n",
      "80 0.0424922 [ 1.2387445] [-0.54297835]\n",
      "100 0.038592 [ 1.22760522] [-0.51742476]\n",
      "120 0.0350499 [ 1.21691644] [-0.49310425]\n",
      "140 0.0318329 [ 1.20672274] [-0.46992984]\n",
      "160 0.0289111 [ 1.19700766] [-0.44784471]\n",
      "180 0.0262576 [ 1.18774915] [-0.42679772]\n",
      "200 0.0238475 [ 1.17892551] [-0.4067398]\n",
      "220 0.0216587 [ 1.17051673] [-0.38762459]\n",
      "240 0.0196708 [ 1.16250277] [-0.36940759]\n",
      "260 0.0178653 [ 1.15486598] [-0.3520467]\n",
      "280 0.0162255 [ 1.14758778] [-0.33550182]\n",
      "300 0.0147363 [ 1.14065158] [-0.31973442]\n",
      "320 0.0133837 [ 1.13404155] [-0.30470803]\n",
      "340 0.0121553 [ 1.12774217] [-0.2903879]\n",
      "360 0.0110397 [ 1.12173843] [-0.2767407]\n",
      "380 0.0100264 [ 1.11601734] [-0.26373479]\n",
      "400 0.00910613 [ 1.11056495] [-0.25134009]\n",
      "420 0.00827032 [ 1.10536873] [-0.239528]\n",
      "440 0.00751123 [ 1.10041678] [-0.22827108]\n",
      "460 0.00682182 [ 1.09569764] [-0.21754313]\n",
      "480 0.00619569 [ 1.09120023] [-0.20731941]\n",
      "500 0.00562703 [ 1.08691418] [-0.1975762]\n",
      "520 0.00511055 [ 1.08282959] [-0.18829083]\n",
      "540 0.0046415 [ 1.0789367] [-0.17944185]\n",
      "560 0.00421547 [ 1.07522702] [-0.17100874]\n",
      "580 0.00382856 [ 1.07169163] [-0.16297194]\n",
      "600 0.00347716 [ 1.06832242] [-0.15531288]\n",
      "620 0.00315801 [ 1.06511152] [-0.14801371]\n",
      "640 0.00286816 [ 1.06205165] [-0.1410576]\n",
      "660 0.00260491 [ 1.0591352] [-0.1344284]\n",
      "680 0.00236581 [ 1.05635607] [-0.12811072]\n",
      "700 0.00214867 [ 1.0537076] [-0.12209]\n",
      "720 0.00195146 [ 1.05118346] [-0.11635224]\n",
      "740 0.00177235 [ 1.04877806] [-0.11088407]\n",
      "760 0.00160967 [ 1.04648566] [-0.10567289]\n",
      "780 0.00146193 [ 1.04430103] [-0.10070667]\n",
      "800 0.00132775 [ 1.04221916] [-0.09597385]\n",
      "820 0.00120589 [ 1.04023528] [-0.09146365]\n",
      "840 0.00109521 [ 1.03834403] [-0.08716518]\n",
      "860 0.000994684 [ 1.03654206] [-0.08306868]\n",
      "880 0.000903386 [ 1.03482473] [-0.07916477]\n",
      "900 0.00082047 [ 1.03318799] [-0.0754443]\n",
      "920 0.000745163 [ 1.03162837] [-0.07189868]\n",
      "940 0.00067677 [ 1.03014183] [-0.06851967]\n",
      "960 0.00061465 [ 1.02872539] [-0.06529948]\n",
      "980 0.000558237 [ 1.02737546] [-0.06223066]\n",
      "1000 0.000507004 [ 1.02608895] [-0.05930611]\n",
      "1020 0.000460466 [ 1.02486277] [-0.05651897]\n",
      "1040 0.000418205 [ 1.0236944] [-0.0538628]\n",
      "1060 0.000379821 [ 1.02258086] [-0.05133144]\n",
      "1080 0.000344959 [ 1.02151978] [-0.04891913]\n",
      "1100 0.000313297 [ 1.02050817] [-0.0466201]\n",
      "1120 0.000284537 [ 1.01954412] [-0.04442897]\n",
      "1140 0.000258424 [ 1.01862574] [-0.04234087]\n",
      "1160 0.000234702 [ 1.01775038] [-0.04035094]\n",
      "1180 0.000213161 [ 1.01691616] [-0.03845458]\n",
      "1200 0.000193596 [ 1.01612127] [-0.03664736]\n",
      "1220 0.000175828 [ 1.01536357] [-0.03492509]\n",
      "1240 0.000159689 [ 1.01464152] [-0.03328371]\n",
      "1260 0.000145031 [ 1.01395345] [-0.03171948]\n",
      "1280 0.00013172 [ 1.0132978] [-0.03022881]\n",
      "1300 0.000119631 [ 1.01267278] [-0.02880818]\n",
      "1320 0.00010865 [ 1.01207721] [-0.02745432]\n",
      "1340 9.86783e-05 [ 1.01150966] [-0.02616407]\n",
      "1360 8.96206e-05 [ 1.0109688] [-0.02493449]\n",
      "1380 8.13962e-05 [ 1.01045334] [-0.0237627]\n",
      "1400 7.3926e-05 [ 1.0099622] [-0.02264602]\n",
      "1420 6.71397e-05 [ 1.00949383] [-0.02158176]\n",
      "1440 6.09776e-05 [ 1.00904763] [-0.02056747]\n",
      "1460 5.53807e-05 [ 1.00862241] [-0.01960085]\n",
      "1480 5.02982e-05 [ 1.00821722] [-0.01867966]\n",
      "1500 4.56812e-05 [ 1.0078311] [-0.01780181]\n",
      "1520 4.14874e-05 [ 1.00746298] [-0.01696518]\n",
      "1540 3.7681e-05 [ 1.00711226] [-0.0161679]\n",
      "1560 3.42223e-05 [ 1.00677812] [-0.01540811]\n",
      "1580 3.10815e-05 [ 1.00645947] [-0.01468403]\n",
      "1600 2.82287e-05 [ 1.00615597] [-0.01399392]\n",
      "1620 2.56379e-05 [ 1.00586665] [-0.01333627]\n",
      "1640 2.32848e-05 [ 1.00559092] [-0.01270952]\n",
      "1660 2.11472e-05 [ 1.00532818] [-0.01211222]\n",
      "1680 1.92062e-05 [ 1.00507784] [-0.01154304]\n",
      "1700 1.74439e-05 [ 1.00483918] [-0.01100061]\n",
      "1720 1.58427e-05 [ 1.00461185] [-0.01048363]\n",
      "1740 1.43891e-05 [ 1.00439513] [-0.00999098]\n",
      "1760 1.30683e-05 [ 1.00418842] [-0.00952147]\n",
      "1780 1.18688e-05 [ 1.00399172] [-0.009074]\n",
      "1800 1.07795e-05 [ 1.00380409] [-0.00864756]\n",
      "1820 9.79043e-06 [ 1.00362539] [-0.00824116]\n",
      "1840 8.8916e-06 [ 1.00345492] [-0.00785388]\n",
      "1860 8.07538e-06 [ 1.00329244] [-0.00748477]\n",
      "1880 7.33435e-06 [ 1.00313783] [-0.007133]\n",
      "1900 6.66113e-06 [ 1.00299037] [-0.00679778]\n",
      "1920 6.04957e-06 [ 1.00284982] [-0.00647834]\n",
      "1940 5.49448e-06 [ 1.00271595] [-0.00617391]\n",
      "1960 4.99051e-06 [ 1.00258839] [-0.00588381]\n",
      "1980 4.53225e-06 [ 1.0024668] [-0.00560736]\n",
      "2000 4.11622e-06 [ 1.00235081] [-0.00534385]\n",
      "[ 5.00641012]\n",
      "[ 2.5005331]\n",
      "[ 1.49818242  3.50288391]\n",
      "0 1.20626 [ 1.06815422] [ 0.01662197]\n",
      "20 0.167739 [ 1.26400983] [ 0.14305848]\n",
      "40 0.14647 [ 1.24762452] [ 0.2059799]\n",
      "60 0.127913 [ 1.23141146] [ 0.26453114]\n",
      "80 0.111708 [ 1.21625626] [ 0.31924659]\n",
      "100 0.097555 [ 1.20209336] [ 0.37037873]\n",
      "120 0.0851955 [ 1.18885803] [ 0.41816226]\n",
      "140 0.0744019 [ 1.17648959] [ 0.46281633]\n",
      "160 0.0649757 [ 1.16493118] [ 0.50454605]\n",
      "180 0.0567438 [ 1.15412974] [ 0.5435428]\n",
      "200 0.0495548 [ 1.14403558] [ 0.5799855]\n",
      "220 0.0432766 [ 1.13460255] [ 0.61404181]\n",
      "240 0.0377937 [ 1.12578738] [ 0.64586759]\n",
      "260 0.0330055 [ 1.11754942] [ 0.67560905]\n",
      "280 0.028824 [ 1.109851] [ 0.70340276]\n",
      "300 0.0251722 [ 1.10265684] [ 0.72937632]\n",
      "320 0.0219831 [ 1.09593379] [ 0.75364876]\n",
      "340 0.019198 [ 1.08965099] [ 0.7763316]\n",
      "360 0.0167657 [ 1.08377981] [ 0.79752874]\n",
      "380 0.0146417 [ 1.07829285] [ 0.81733781]\n",
      "400 0.0127867 [ 1.07316554] [ 0.83584946]\n",
      "420 0.0111667 [ 1.0683738] [ 0.85314894]\n",
      "440 0.00975194 [ 1.06389594] [ 0.86931556]\n",
      "460 0.00851643 [ 1.05971122] [ 0.88442326]\n",
      "480 0.00743747 [ 1.05580068] [ 0.89854157]\n",
      "500 0.00649521 [ 1.05214643] [ 0.91173512]\n",
      "520 0.00567233 [ 1.04873121] [ 0.92406476]\n",
      "540 0.00495367 [ 1.04553974] [ 0.93558687]\n",
      "560 0.00432608 [ 1.04255736] [ 0.94635445]\n",
      "580 0.00377799 [ 1.03977013] [ 0.9564169]\n",
      "600 0.00329934 [ 1.03716564] [ 0.96582043]\n",
      "620 0.00288133 [ 1.03473151] [ 0.97460806]\n",
      "640 0.00251628 [ 1.03245687] [ 0.98282003]\n",
      "660 0.0021975 [ 1.03033137] [ 0.99049419]\n",
      "680 0.00191909 [ 1.02834487] [ 0.99766576]\n",
      "700 0.00167595 [ 1.02648854] [ 1.00436771]\n",
      "720 0.00146362 [ 1.02475381] [ 1.01063085]\n",
      "740 0.00127819 [ 1.02313256] [ 1.0164839]\n",
      "760 0.00111624 [ 1.02161765] [ 1.0219537]\n",
      "780 0.000974824 [ 1.02020168] [ 1.02706516]\n",
      "800 0.000851309 [ 1.01887858] [ 1.03184199]\n",
      "820 0.000743449 [ 1.01764226] [ 1.0363059]\n",
      "840 0.000649265 [ 1.01648688] [ 1.04047704]\n",
      "860 0.000567013 [ 1.0154072] [ 1.04437518]\n",
      "880 0.000495175 [ 1.0143981] [ 1.04801798]\n",
      "900 0.000432446 [ 1.01345527] [ 1.05142224]\n",
      "920 0.000377659 [ 1.01257408] [ 1.05460346]\n",
      "940 0.000329813 [ 1.0117507] [ 1.05757642]\n",
      "960 0.000288028 [ 1.01098108] [ 1.06035459]\n",
      "980 0.000251537 [ 1.01026213] [ 1.06295097]\n",
      "1000 0.000219669 [ 1.00958979] [ 1.06537747]\n",
      "1020 0.000191842 [ 1.0089618] [ 1.06764483]\n",
      "1040 0.000167538 [ 1.00837493] [ 1.06976354]\n",
      "1060 0.00014631 [ 1.00782645] [ 1.07174397]\n",
      "1080 0.000127773 [ 1.00731385] [ 1.07359445]\n",
      "1100 0.000111587 [ 1.00683486] [ 1.07532358]\n",
      "1120 9.74505e-05 [ 1.00638735] [ 1.07693958]\n",
      "1140 8.51052e-05 [ 1.00596905] [ 1.07844973]\n",
      "1160 7.43216e-05 [ 1.00557816] [ 1.07986116]\n",
      "1180 6.49075e-05 [ 1.0052129] [ 1.08117998]\n",
      "1200 5.66843e-05 [ 1.00487137] [ 1.0824126]\n",
      "1220 4.95019e-05 [ 1.00455236] [ 1.0835644]\n",
      "1240 4.32285e-05 [ 1.00425422] [ 1.08464098]\n",
      "1260 3.77517e-05 [ 1.00397551] [ 1.08564687]\n",
      "1280 3.29703e-05 [ 1.00371516] [ 1.08658695]\n",
      "1300 2.87919e-05 [ 1.00347185] [ 1.08746541]\n",
      "1320 2.51432e-05 [ 1.00324452] [ 1.08828628]\n",
      "1340 2.19586e-05 [ 1.00303209] [ 1.08905339]\n",
      "1360 1.91774e-05 [ 1.00283349] [ 1.08976984]\n",
      "1380 1.67492e-05 [ 1.00264812] [ 1.09043968]\n",
      "1400 1.46275e-05 [ 1.00247467] [ 1.09106565]\n",
      "1420 1.27746e-05 [ 1.00231254] [ 1.09165072]\n",
      "1440 1.11571e-05 [ 1.00216115] [ 1.09219742]\n",
      "1460 9.74333e-06 [ 1.00201964] [ 1.09270847]\n",
      "1480 8.50823e-06 [ 1.00188732] [ 1.09318614]\n",
      "1500 7.43055e-06 [ 1.00176382] [ 1.09363234]\n",
      "1520 6.48828e-06 [ 1.00164819] [ 1.09404933]\n",
      "1540 5.66668e-06 [ 1.0015403] [ 1.09443891]\n",
      "1560 4.94958e-06 [ 1.00143945] [ 1.09480298]\n",
      "1580 4.32245e-06 [ 1.00134528] [ 1.0951432]\n",
      "1600 3.77489e-06 [ 1.00125718] [ 1.09546125]\n",
      "1620 3.29661e-06 [ 1.00117481] [ 1.09575856]\n",
      "1640 2.87886e-06 [ 1.00109792] [ 1.09603631]\n",
      "1660 2.51408e-06 [ 1.00102603] [ 1.09629595]\n",
      "1680 2.1958e-06 [ 1.0009588] [ 1.09653854]\n",
      "1700 1.91727e-06 [ 1.00089598] [ 1.09676516]\n",
      "1720 1.67477e-06 [ 1.00083745] [ 1.09697688]\n",
      "1740 1.46263e-06 [ 1.00078261] [ 1.09717488]\n",
      "1760 1.27756e-06 [ 1.00073135] [ 1.09735966]\n",
      "1780 1.11563e-06 [ 1.00068343] [ 1.09753251]\n",
      "1800 9.74357e-07 [ 1.00063884] [ 1.09769416]\n",
      "1820 8.50927e-07 [ 1.000597] [ 1.09784496]\n",
      "1840 7.43332e-07 [ 1.0005579] [ 1.09798586]\n",
      "1860 6.4905e-07 [ 1.00052142] [ 1.09811783]\n",
      "1880 5.67201e-07 [ 1.00048733] [ 1.09824085]\n",
      "1900 4.95281e-07 [ 1.0004555] [ 1.09835601]\n",
      "1920 4.32518e-07 [ 1.0004257] [ 1.09846365]\n",
      "1940 3.77823e-07 [ 1.0003978] [ 1.09856403]\n",
      "1960 3.3004e-07 [ 1.00037169] [ 1.09865797]\n",
      "1980 2.88252e-07 [ 1.0003475] [ 1.09874582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2.51745e-07 [ 1.00032473] [ 1.09882784]\n",
      "[ 6.10045147]\n",
      "[ 3.59963965]\n",
      "[ 2.59931493  4.59996414]\n",
      "Mac Address : 98-83-89-2D-5E-D9\n"
     ]
    }
   ],
   "source": [
    "# Lab 2 Linear Regression\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Try to find values for W and b to compute y_data = W * x_data + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let's use TensorFlow to figure it out\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                            Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n",
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n",
    "print (\"Mac Address : \" +get_mac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem04\n",
    "- Code in lab-02-3-linear_regression_tensorflow.org.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n",
      "Mac Address : 98-83-89-2D-5E-D9\n"
     ]
    }
   ],
   "source": [
    "# From https://www.tensorflow.org/get_started/get_started\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = x * W + b\n",
    "\n",
    "# cost/loss function\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y))  # sum of the squares\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)  # reset values to wrong\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\" % (curr_W, curr_b, curr_loss))\n",
    "print (\"Mac Address : \" +get_mac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mac Address\n",
    "![title](image/MacAddress.JPG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
